                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [{"title":"Google 三轮车之 MapReduce","date":"2020-06-01T13:30:01.000Z","url":"/2020/06/01/mapreduce/","tags":["mapreduce","distributed system"],"categories":["笔记本"],"content":"重读 mapreduce，在实现 mapreduce demo 之后。论文里最重要的部分就是这张图了，可以说 mapreduce 的精髓就在这里。从这张图就可以勾勒出 mapreduce 的整体架构和数据处理流程。执行流程首先，输入数据会被自动分成 M 片，然后并行的在不同的机器上执行，执行 map 的时候根据 key 不同分配到不同的 reduce 进行处理。首先 mapreduce 库把输入文件分成 M 块大小在 16-64mb 的文件。master 节点向 workers 节点分发 map/reduce 任务。map 节点读取对应的任务切片然后交给 map 函数处理。得到的中间 kv 对存放在缓存。缓存会被分成 R 片定期写入 worker 的本地磁盘，本地磁盘的地址最后会返回给 master。当 reduce 节点被 master 通知中间 kv 对的地址时，会通过 rpc 调用读取 kv 对到本地磁盘，只有当 reduce 节点读取到所有的 kv 对后，首先对 kv 对进行排序，这里就完成了 list(k2, v2) -&gt; (k2, list(v2)) 的转变。注：对于 M 个分片，会产生 M * R 个中间文件，reduce 节点需要读到 M 个中间文件才算读取完毕。遍历所有的 (k2, list(v2)) 将 k2, list(v2) 丢到 reduce 函数处理，得到的结果添加到当前 reduce 结果的末尾。当所有的 map 任务和 reduce 任务完成后，master 节点唤醒用户程序并返回。Falut ToleranceWorker Failuremaster 节点会使用心跳包机制检查 worker 是否存活，如果一段时间内检测到某个 worker 死亡，会把 worker 当前执行的任务交由其他 worker 处理。当 map task 失败的时候，会把该任务重新调度到其他 worker 执行，任何正在执行和当前 map task 相关的 reducer worker 会重新执行，并从新的 map worker 读取数据。Master Failure由于当前只有一个 Master，可以采用定时做 checkpoint ，并用 GFS 来保证由多个主机有 Master 文件的备份，即使 Master 挂掉也可以从其他机器上进行恢复。Semantics in the Presence of Failures保证在 mapreduce 执行过程中，即使发生了错误，也和没有发生错误时的结果一致。举个例子，当某个 map 任务失败当时候，该任务被调度到其他 worker 执行，不能让当前 map 任务的失败影响到后续执行。当 map 任务完成当时候，worker 会向 master 节点发送包含 r 个咋临时文件文件名当信息，master 检测到是否在数据结构中，然后添加，这样保证了，即使 map 失败，由于 master 数据结构修改到原子性，master 没有包含该文件的信息。后续 reduce 也不会读到这些文件。当 reduce 任务完成的时候，采用原子改名策略，只有当任务完成才会对文件进行改名。Locality局部性原理，因为 mapreduce 基于 GFS，可以利用 GFS 每个文件有三个副本的特性，当需要调度任务的时候会优先将任务调度到目标文件已经存在到机器上，减小网络数据传输到开销。Backup Tasks当整个任务接近完成当时候，可能因为某些主机的软/硬件错误导致部分任务执行过长影响结束时间，这时候会采取 backup tasks 策略，即接近完成当时候，每个任务会被同时放到两台主机上运行，如将 mr-0-1 放到 worker 1 worker 2 执行，任何一个 worker 结束时即表示完成。Referencemapreduce"},{"title":"ARIES","date":"2020-05-26T10:48:14.000Z","url":"/2020/05/26/aries/","tags":["database","transaction","aries"],"categories":["笔记本"],"content":"大概是 ARIES 论文的阅读笔记。ARIES 中的数据结构老生常谈的东西了，包含以下几样：LSN: log 的唯一标识符。Type: 用来区分 log 的类型。TxnIDPrevLsn: 同事务的上一条 log，在 undo 中可以减少我们寻找下一条需要被 undo 的log 所需的时间。pageIdpageLSN: 可以加速 redo, 在没有 dpt 辅助的情况下，如果此时我们不存在 pageLSN，那么找到 redo start 的唯一方法就是，从 checkpoint 向后扫描 log, 根据 log 找出在 checkpoint 后未结束的事务，然后从 checkpoint 向前扫描， 找到这些事务对页发生修改的最早的 lsn。这样还有一个问题，当我们进行 redo 的时候，可能会发生重复 redo 破坏数据的一致性。UndoNextLSN: 在 CLR log 中，用于指定下一条需要被 undo 的 log。transcation table: 在 checkpoint 当中被用到，表中每个条目维护一个 tid, lastlsn，undoNextLsn, 用这个表我们可以找到每个事务最后一条 log 所在位置，方便进行 undo。dirty page table: 脏页表，每个条目记录第一次使该页不同于硬盘上的页的 lsn。该表可以让我们在恢复的时候更加方便的找到 redo start。Updates更新记录的基本操作如下这么做是为了保证日志的顺序和对页更新的顺序一致，如果顺序不一致，在 redo 的时候不一定能保证事务的一致性，比如写入覆盖这个问题。同时，注意修改 pageLsn 一定在 page 被修改过后，这是由于，考虑如下情况那么恢复的时候会认为该页的最后一条记录已经反应到磁盘上了，但实际上我们只修改了 pagelsn，具体内容对修改并没有反映到磁盘上。在对记录更新对时候，有一种特殊情况：插入，由于在插入数据之前我们并不知道它的 oid, 所以无法对其进行 lock，只有在我们获取了该页的 latch 并且知道插入位置之后才能获取到 lcok，但是在这种情况下可能会产生死锁。而且这种死锁不能被 lockmanager 所探测到。解决的方法如下，当我们向 lockmanager 发送一个立即返回的 condition lock 请求，此处的 condition 可以为 page.freeSpace() &gt; tuple.Size() &amp;&amp; dstSlot.free() 如果接受，那么按正常操作继续。如果没有，释放 latch，获取一个正常的 lock，该lock返回之后获取 latch，并检查该 slot 是否可用，如果不可用，则重复上述步骤（感觉自己理解还是有问题，原文如下）T o avoid waiting for a lock while holding a latch, which could lead to an undetected deadlock, the lock is requested conditionally, and if it is not granted, then the latch is released and the lock is requested unconditionally. Once the unconditionally requested lock is granted, the page is latched again, and any previously verified conditions are rechecked. This rechecking is required beacuse, after the page was unlatched, the conditions could have changed. The page_LSN, on relatching, if any changeds could have possibly occurred. If the conditions are still found to be satisfied for performing the update, it is performed as described above. Ohterwise, corrective actions are taken. If the conditionally requested lock is granted immediately, then the update can proceed as before.Total or Partial Rollbacks基本操作如下rollback 部分比较简单，不过这里 writelog 的时间点和前面有所不同，只有在操作被 undo 之后才会写 clr log，同时 clr log 里的 undoNextLSN 非常重要，当我们 total rollback 但中途 crash 的时候，我们可以利用 txnTable 里的 lastLsn，直接找到对应下一条该重做的 log，提升了恢复速度。为什么要在 undo 之后写 log，主要原因和上面差不多，如果提前写 log，就会存在虚空 undo 的情况，导致少撤销一条操作。CheckpointsARIES 采取了 fuzzy checkpoint 技术，fuzzy checkpoint 也就是说，当我们进行 checkpoint 操作的时候不需要 stw，我们只是记录一些元信息，方便更快的恢复，不过这也需要和 bufferpoolmanager 进行配合，需要 bpm 定时向硬盘写入 pagebuffer，减少恢复所需的工作量。fuzzy checkpoint 的基本操作如下，当系统进行 checkpoint 操作的时候，首先向日志写入 checkpoint_start, 然后写入 dirty page table, txn table，之后标注 checkpoint_end, 最后将 master-record 指向的记录改为当前 checkpoint_start 所在位置。Analysis Pass这阶段的目的是完善 dpt 和 txnTable, 当我们 crash 的时候，checkpoint 之后的操作也需要进行 redo 和 undo，而这部分的信息并没有包含在 checkpoint 的两张表内，我们需要借助当前 pass 进行补全。当前 pass 会产生 txnTable, dpt, redoLsn 三个数据结构，用于接下来两个 pass 的操作。 redoLsn 是在 dpt 里最小的 reclsn，如果 dpt 为空，也就是说没有修改发生，那么我们就没必要进行 redo。当前 pass 如何构造 dpt, txnTabledpt: 对遇到的每条记录，如果所做修改的的页没有在 dpt 中出现，dpt.append(lsn, lsn)txnTable: 对遇到的每条记录，如果指明了某个事务结束，则从 txnTable 中移除，否则更新 txntable 的状态，即更新 txnTable 对应条目的 undoNextLsn, lastLsn, stateRedo Passredo 只需要从 redoLsn 开始向后重做就好了，不过要检查几个要素，要被 redo 的页是否在 dpt 中，当前 lsn 是否大于等于该页的 recLsn，该页的 pageLsn 是否小于该 log 的lsn。当我们 redo 的时候，有可能会从 checkpoint 前某个点开始 redo，这样就会造成部分页已经被写入了硬盘并且日后也未被修改，所以 checkpoint 的时候不在 dpt 当中，不需要被修改。关于 pageLsn，如果 pageLsn 大于当前 lsn，即证明该条记录所做的操作已经落盘，不需要进行重做，而且我们的 recLsn 需要更新，更新为比 pageLsn 大一点的记录。由于 pageLsn 只在 redo 的时候需要，这么做也是可以的。redo 部分可以发挥并行优势，因为我们的 redo 是面向 page 的，也就是说对于 dpt 的所有 page，我们都可以进行并行操作，只要事先/或者流水线 准备好对应 page 的 log queue，依次执行即可。Undo Pass因为之前的 redo pass, 当前要做的只是把 crash 时刻没有完成的事务撤销而已。undo 部分的操作和前面 rollback 基本一致，不同的是这里取得 undoNextLsn 是从 txnTable。Checkpoints During RestartAnalysis Pass 在完成这个 pass 之后，我们将现在的 dpt/txnTable 写入到硬盘上，这样下次恢复的时候就可以跳过 Analysis pass.Redo Pass 每次 bufferpool 向磁盘写入修改过后的页的时候，就更新该页的记录为当前 log 的下一条记录，由于 redo 是从前往后，所以同样保证了 wal 的性质。并且，在这种情况下，我们下次重启的时候就可以少一些 redo。其他记录 checkpoint 相关的记录保持不变。Undo Pass 在启动 undo pass 的时候，将 dpt 更新为现在 bufferpoll 的 dpt，很容易理解，在下次进行重启操作的时候只要由于前面两个 pass 的操作，可以减少工作量。原文ARIES : A Transaction Recovery Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging"},{"title":"为什么我们要计算 First Set/ Follow Set","date":"2020-03-16T05:33:34.000Z","url":"/2020/03/16/firstfllow/","tags":["compiler","recursive descent"],"categories":["笔记本"],"content":"在递归下降 parse 当中，在某些情况下，我们会计算 First Set/ Follow Set。为什么要计算它们呢？假设我们有如下语法首先，注意到 B production 是一个左递归，递归下降不能处理左递归的情况。得把 B 变为右递归，我们做如下变化First Set当我们获得第一个 token 的时候，首先要和 S 进行匹配，但此时 AB 都是非终结符，我们需要一种可以和现有 token 匹配但方法，这就是 First set（first集），我们把 tkn 和 First(A) 进行匹配，完成我们递归下降的过程。理解到了 First 集合的含义，那如何计算 First 集也是信手拈来。First(A) 就是，按照 A 的推到走下去，可能遇到的第一个终结符。匹配 A 会有哪些终结符。我们的两个集合都是为了匹配 token 服务的。那么很容易得到计算 First(A) 的方法：注意这里，当 C 为 ε 的时候，下一个要匹配的就变成了 a。Follow SetFollow Set 是为了解决我们推到过程中遇到一个非终结符，这个非终结符可能为 ε 诞生的，它同样是计算接下来要可能的终结符。举个例。假设 A 为空，A 后可能为 C, B。"},{"title":"NFA & DFA","date":"2020-03-14T11:28:53.000Z","url":"/2020/03/14/NFA-DFA/","tags":["NFA","DFA","compiler"],"categories":["笔记本"],"content":"看 DFA, NFA 有点头大，记一下，理一下流程。NFANFA 可被 $(Q,\\Sigma, T, q0, F)$ 定义，其中$Q$ 为状态的有限集合$\\Sigma$ 为输入字符集$T$ 为转移函数， 可以表示为 $Q\\times \\Sigma \\to P(Q)$ ，因为每个状态有输入和输出，输入为$\\Sigma$，输出就是下一个状态，在 NFA 中，下一个状态不唯一，所以下个状态表示为 $P(Q)$ ，也就是说 $Q$ 的幂集合$q_0$ 为起始状态在带有 $\\varepsilon$移动 的状态下，NFA 可被扩展为 $NFA-\\varepsilon$ 或者说 $NFA-\\lambda$ ，那么此时的 $T$ 可以表示为 $Q\\times (\\Sigma \\cup \\{\\varepsilon\\}) \\to P(Q)$$\\varepsilon$ 移动， 即使说一个状态在没有输入的状况下转化为其他状态，也就是说，当前状态不确定，薛定谔的状态DFADFA 和 NFA 可以互相转化，与 NFA 不同，DFA 在一个输入下只有唯一的一种后继状态，DFA 可以表示为 $Q\\times\\Sigma\\to Q$ 由于 DFA 的性质，还可以写成 $Q\\times\\Sigma^{*}\\to Q$ NFA to DFA即由 $Q\\times\\Sigma\\to P(Q)\\Rightarrow Q\\times\\Sigma\\to Q$，很显然的一个想法是令$Q\\in P(Q)$，也就是说，把 NFA 中由一个输入产生的多个后继状态在不改变 NFA 的情况下组合成一个。这种转换的方法叫幂集构造，由上述公式的变化，易知：如果我们有一个$n$个状态的 NFA，当把它变为 DFA 的时候，我们最多会有 $2^n$ 个状态。如何应用 DFA 来识别 token ?首先我们要把语言划分成不同到成分，即不同到 class，然后如何识别呢？对于每个 class 我们可以定义相应到 DFA ，这可以用语言自带的库实现，比如字符串对比，正则表达式。然后我们只要把不同部分的 DFA 组合到一起形成一个大的 DFA 就可以了。例子在对 sql 进行词法分析对过程中，有个例子就是，当输入为[a-zA-Z]的时候，下一个状态是不确定的，有可能为 Identifier 也可能为 Keyword，即如下 NFA通过魔法，可以转化为如下 DFA实际上，在转换为 DFA 之后，switch 写一下 lexer 就写完了。最近正好在写 sql 的 lexer，看到了几个例子，这里记一下。在 SQL 里，如何快速识别出关键字(KEYWORD)是分析速度最大的影响因素。我看到有两种实现。用 hash 表实现，$O(1)$用 字典🌲 实现， $O(1)$顺序查找，$O(N)$字典树是跑的最快的，因为 hash 表在最差的情况下可能到 $O(N)$ ，当然这也要看 hash 表到实现，但是字典树到最差情况就是 $O(max(len(keyword)))$ ，只要$max(len(keyword))&lt;num_keywords$ 那么字典树就绝对更快。 ping-cap 的 sql parser 就是这么写的。ref:DFA wikiNFA wikipingcap sqlparser"},{"title":"CSAPP-shell-lab","date":"2019-10-28T12:30:02.000Z","url":"/2019/10/28/CSAPP-shell-lab/","tags":["OS","CSAPP"],"categories":["笔记本"],"content":"记录一下 shell lab 流程mainmain 函数里跑了个死循环，不断读取内容并送到 eval() 处理。evaleval() 函数是 shell 主要的处理函数，处理流程如下代码如下，有两个点需要注意一下。在创建新的线程处理 cmdline 之前，阻塞 chld 防止新线程结束之后，父进程将已经结束的子进程的 pid 加入 job list防止由于 &lt;C-z&gt; &lt;C-c&gt; 而导致子进程未添加到 job list 而成为孤儿进程waitfg这个函数要等待前台函数返回我们用 sigsuspend(sigset_t *) 函数直接挂起父进程，等待子进程结束，然后控制交由父进程。sigsuspend(sigset_t *)可以理解为，挂起当前进程直到出现了 mask 内没有屏蔽的信号。    sigchld_handler这个函数用于处理 sig_chld 信号，也即是说子进程结束时的处理。主要注意子进程退出的三种情况程序正常和由于信号退出，这时候字节把子进程从 job_list 中移除即可程序停止，更新一下状态即可。do_bgfg这是程序处理前后台进程的主要函数，这个函数的处理逻辑也很简单，我们只需要找到进程的 pid，让他继续运行即可，bg/fg 区别只在父进程等待。"},{"title":"CSAPP cache lab","date":"2019-10-22T02:32:07.000Z","url":"/2019/10/22/CSAPP-cache-lab/","tags":["OS","CSAPP"],"categories":["笔记本"],"content":"最近把csapp的cachae lab写完了，记录一下。lab主要有两个部分，一个是 cache simulator，另一个是矩阵转置的缓存优化。cache simulatro核心逻辑还是很简单的，主要是如何实现 LRU 的问题。基本上用时间优先队列就完事了，最后操作的放到最前面。核心代码如下optimize matrix题目给了一个 E=1,b=5,s=5 的缓存，我们要利用缓存优化矩阵转置代码。tagsetblock54552^543232size of cache line: 32 bytestotal size: 32*32 bytesint num: 32*8 = 25632x3232x32 的优化如下，主要注意一个缓存行可以装下八个整数。而 C 语言里的矩阵又是按照行存储的，也就是说，当我们读第一个整数的时候，同一行后面的 7 个整数也会被读入到缓存行里，当下一次访问同一行的时候就会缓存命中。64x648x8refCache Lab 解题报告"},{"title":"简单rop","date":"2019-09-29T06:15:25.000Z","url":"/2019/09/29/简单rop/","tags":["OS","pwn"],"categories":["笔记本"],"content":"最近做了一下 ropemporium 上的题，简单记录一下。0x00 ret2winret2win 有 32 位和 64 位的，两种情况下参数传递的方式不同。ret2win32首先拖到 ida 里看看主要逻辑在 pwnme 里ret 相当于 pop $eippwnme 调用了 fgets ，我们可以利用 fgets 函数进行栈溢出。由于 s 长 0x28 个字节，s 后面就是当前栈帧的 ebp 然后是 ret 时会用到的地址，这样我们就可以让它跳到我们想要的地方，同时这个题啥都没开，payload 就很好糊了。ret2win64这个题解法和上题基本一致，不过有一个区别就是 64 位下，参数通过寄存器传递而不是通过栈传递。payload0x01 splitsplit32同样的栈溢出，我们可以控制返回地址，给了个 usefulfunction注意到调用了 system 函数，我们可以利用 system 函数执行代码，这个时候我们从 .data 段找我们需要的数据payload 如下split6464位，我们这次要把数据通过 rdi 传进 system 函数，所以我们要找到一个能够把数据从栈弄到寄存器。偏移 40.datapayload0x02 callme依次调用 callme_one(), callme_two(), callme_three() 参数 1, 2, 3即可。callme3232 位要注意平衡栈，可以考虑 3 个 pop，或者 add esp, $8callme64这题比较蠢，找个 pop rdi; pop rsi; pop rdx; ret; 的就完事了。"},{"title":"socks5","date":"2019-05-21T14:07:48.000Z","url":"/2019/05/21/socks5/","tags":["network","protocol"],"categories":["笔记本"],"content":"socks5在[rfc1928]有详细的说明。这里只对socks5协议做简单解释，只是抽取了部分rfc中的内容进行翻译。1 使用场景socks5协议的设计初衷是在一个有防火墙的网络中，希望能通过某种方法来提高部分人的网络权限，让这部分人能够安全透明的访问外网。大概是这样的不过国内大多数都是反着用的（笑socks5流程TCP部分协商客户端发送一条请求与socks服务器协商认证方法，请求结构如下。VERNMETHODSMETHODS111 to 255字段解释：VER:socks的版本号，socks为X’05’，长度1字节NMETHODS:认证方法数目，长度1字节METHODS:认证方法，1到255字节服务端从客户端提供的方法中选择一个并返回，返回结构如下。VERMETHOD11可选认证方法如下：X’00’: NO AUTHENTICATION REQUIREDX’01’: GSSAPIX’02’: username/passwordX’03’-X’7F’: IANA assignedX’80’-X’FE’: RESERVED FOR PRIVATE METHODSX’FF’: NO ACCEPTABLE METHODS认证认证部分的说明在[rfc1929]如果客户端选择了username/password认证，那么客户端的请求是长这个样子的VERULENUNAMEPLENPASSWD111to25511to255字段解释：xVER:子协议版本，这里为X’01’ULEN: UNAME字段长度UNAME: 用户名字节数据PLEN: PASSWD字段长度PASSWD: 密码字节数据比较蠢的是，这东西都是明文传输的，这在rfc1929里也有提到服务端返回VERSTATUS11字段解释：VER: 同上STAUTS: X’00’代表认证成功，其他都表示失败请求针对所依赖方法的子协商一旦完成，客户端就发送请求细节。如果协商过的方法包含了针对完整性检查或保密性目的的封装，这些请求必须被包装到所依赖的方法的封装中。SOCKS请求按下述格式进行组织VERCMDRSVATYPDST.ADDRDST.PORT11X’00’1Variable2字段解释：VER: 协议版本号，这里为X’05’CMD: CONNECT: X’01’BIND: X’02’UDP ASSOCIATE: X’03’RSV: X’00’ATYP: 地址类别(ipv4/ipv6/domainname/ipv9)IPV4: X’01’DOMAINNAME: X’03’IPV6: X’04’DST.ADDR: 目的地址DST.PORT: 目的端口号请求类型有下面几种：CONNECT : 0X01， 建立代理连接。比较常见的请求，客服端请求服务器发起链接到目标主机，目标端口的代理。SOCKS 服务器将使用目标主机，目标端口, 客户端的源地址和端口号来评估 CONNECT 请求是否通过。成功之后后续流量都会被转发到目标主机的目标端口。BIND : 0X02，BIND请求被用于要求客户端接受来自服务器连接的协议中。FTP是一个众所周知的例子，它针对命令和状态报告使用主要的“客户端到服务器”的连接，但是用来响应命令（如LS、GET、PUT命令）的数据传输可以使用一条“服务器到客户端”的连接。只有在完成了connnect操作之后才能进行bind操作，bind操作之后，代理服务器会有两次响应, 第一次响应是在创建socket监听完成之后，第二次是在目标机器连接到代理服务器上之后。.建立流程如下：Client随BIND请求，发送其要绑定的地址和端口。Server返回其创建的监听端口的地址和端口。Server创建的监听端口有连接后，返回该连接的源地址和端口。Server端将上述连接中的流量，发送给client的监听端口。UDP ASSOCIATE : 0x03，用于在UDP中继处理中建立一条关联以处理UDP数据报。返回服务器返回格式如下：VERREPRSVATYPBND.ADDRBND.PORT11X’00’1Variable2字段解释（与请求相同的部分不再赘述）：REP:X’00’: succeededX’01’: general SOCKS server failureX’02’: connection not allowed by rulesetX’03’: Network unreachableX’04’: Host unreachableX’05’: Connection refusedX’06’: TTL expiredX’07’: Command not supportedX’08’: Address type not supportedX’09’-X’FF’: 未被分配UDP部分每个UDP数据包必须有如下请求头：RSVFRAGATYPDST.ADDRDST.PORTDATA211Variable2Variable字段解释:RSV: Reserved X’0000’FRAG: Current fragment numberATYP-DST.PORT: 同上DATA: user data参考[1]:Python编写socks5服务器参考[2]:[rfc1929]参考[3]:[rfc1928]"},{"title":"ss partI","date":"2019-05-21T04:43:26.000Z","url":"/2019/05/21/ss_0x00/","tags":["network"],"categories":["笔记本"],"content":"虽然ss已经去世了很久，但它依旧活在我等网友心中。一直想看看ss的实现方式，本次就通过python版本shadowsocks源码来解读ss，本系列文章会分成几个部分，我会尽可能做到详细。首先祭奠原作者@clowwindy代码为@ziggear的备份版本，版本号为2.8.2，地址在这ss的目录结构shadowsocks的目录如下（部分目录已略去）上图所示的目录除掉了测试文件。ss的基本架构ss是基于socks5协议实现的，但和socks5又有所不同。关于socks5协议的简析在这里在ss的目录中有两个main函数，一个在local.py中，另一个在server.py，这两个组成了ss的基本架构在ss当中，作者把proxy服务器拆成了客户端和服务端两个部分，并把中间传输数据进行加密，由此提高数据的安全性。我们首先就从客户端部分代码看起，为了阅读方便，这里略去部分代码。可以看到，sslocal和ssserver的代码差距不大，逻辑是基本一致的，其实我们稍作思考便可以明白，作为sslocal和ssserver可以复用的地方非常的多，差别就在sslocal要处理socks协议而server端不用。c/s端有一个eventloop，并把dns_resolver,tcp_server,udp_server加入了事件循环，处理事件。让我们从这里开始来了解ss究竟是怎么写的。事件处理事件处理的代码都在eventloop.py里，里面主要对不同系统的io复用都封装成了epoll的形式，方便进行统一的调用。事件处理的主要代码如下，（超时处理已略去）：一旦poll中有事件触发，就通过该事件的文件描述符去寻找对应的handler，并通过handler.handle_event处理该事件。handle_event在tcp_relay.pyTCP服务器当在eventloop中的handler是和TCP有关时，会调用tcp_relay.py中的hanlde_event函数，如果该socket是指向自己的，那么说明有新的链接，创建一个新的hanlder并对其进行处理。如果不是，就找到与之对应的hanlder处理UDP服务器UDP对事件的处理更简单，就分成client和server异步DNS简单的错误处理，没出错就直接丢给_handle_data()ref[1]shadowsocks源码分析-协议与结构"}]