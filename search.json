                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [{"title":"Google 三轮车之 MapReduce","date":"2020-06-01T13:30:01.000Z","url":"/2020/06/01/mapreduce/","tags":["mapreduce","distributed system"],"categories":["笔记本"],"content":"重读 mapreduce，在实现 mapreduce demo 之后。论文里最重要的部分就是这张图了，可以说 mapreduce 的精髓就在这里。从这张图就可以勾勒出 mapreduce 的整体架构和数据处理流程。执行流程首先，输入数据会被自动分成 M 片，然后并行的在不同的机器上执行，执行 map 的时候根据 key 不同分配到不同的 reduce 进行处理。首先 mapreduce 库把输入文件分成 M 块大小在 16-64mb 的文件。master 节点向 workers 节点分发 map/reduce 任务。map 节点读取对应的任务切片然后交给 map 函数处理。得到的中间 kv 对存放在缓存。缓存会被分成 R 片定期写入 worker 的本地磁盘，本地磁盘的地址最后会返回给 master。当 reduce 节点被 master 通知中间 kv 对的地址时，会通过 rpc 调用读取 kv 对到本地磁盘，只有当 reduce 节点读取到所有的 kv 对后，首先对 kv 对进行排序，这里就完成了 list(k2, v2) -&gt; (k2, list(v2)) 的转变。注：对于 M 个分片，会产生 M * R 个中间文件，reduce 节点需要读到 M 个中间文件才算读取完毕。遍历所有的 (k2, list(v2)) 将 k2, list(v2) 丢到 reduce 函数处理，得到的结果添加到当前 reduce 结果的末尾。当所有的 map 任务和 reduce 任务完成后，master 节点唤醒用户程序并返回。Falut ToleranceWorker Failuremaster 节点会使用心跳包机制检查 worker 是否存活，如果一段时间内检测到某个 worker 死亡，会把 worker 当前执行的任务交由其他 worker 处理。当 map task 失败的时候，会把该任务重新调度到其他 worker 执行，任何正在执行和当前 map task 相关的 reducer worker 会重新执行，并从新的 map worker 读取数据。Master Failure由于当前只有一个 Master，可以采用定时做 checkpoint ，并用 GFS 来保证由多个主机有 Master 文件的备份，即使 Master 挂掉也可以从其他机器上进行恢复。Semantics in the Presence of Failures保证在 mapreduce 执行过程中，即使发生了错误，也和没有发生错误时的结果一致。举个例子，当某个 map 任务失败当时候，该任务被调度到其他 worker 执行，不能让当前 map 任务的失败影响到后续执行。当 map 任务完成当时候，worker 会向 master 节点发送包含 r 个咋临时文件文件名当信息，master 检测到是否在数据结构中，然后添加，这样保证了，即使 map 失败，由于 master 数据结构修改到原子性，master 没有包含该文件的信息。后续 reduce 也不会读到这些文件。当 reduce 任务完成的时候，采用原子改名策略，只有当任务完成才会对文件进行改名。Locality局部性原理，因为 mapreduce 基于 GFS，可以利用 GFS 每个文件有三个副本的特性，当需要调度任务的时候会优先将任务调度到目标文件已经存在到机器上，减小网络数据传输到开销。Backup Tasks当整个任务接近完成当时候，可能因为某些主机的软/硬件错误导致部分任务执行过长影响结束时间，这时候会采取 backup tasks 策略，即接近完成当时候，每个任务会被同时放到两台主机上运行，如将 mr-0-1 放到 worker 1 worker 2 执行，任何一个 worker 结束时即表示完成。Referencemapreduce"},{"title":"ARIES","date":"2020-05-26T10:48:14.000Z","url":"/2020/05/26/aries/","tags":["database","transaction","aries"],"categories":["笔记本"],"content":"大概是 ARIES 论文的阅读笔记。ARIES 中的数据结构老生常谈的东西了，包含以下几样：LSN: log 的唯一标识符。Type: 用来区分 log 的类型。TxnIDPrevLsn: 同事务的上一条 log，在 undo 中可以减少我们寻找下一条需要被 undo 的log 所需的时间。pageIdpageLSN: 可以加速 redo, 在没有 dpt 辅助的情况下，如果此时我们不存在 pageLSN，那么找到 redo start 的唯一方法就是，从 checkpoint 向后扫描 log, 根据 log 找出在 checkpoint 后未结束的事务，然后从 checkpoint 向前扫描， 找到这些事务对页发生修改的最早的 lsn。这样还有一个问题，当我们进行 redo 的时候，可能会发生重复 redo 破坏数据的一致性。UndoNextLSN: 在 CLR log 中，用于指定下一条需要被 undo 的 log。transcation table: 在 checkpoint 当中被用到，表中每个条目维护一个 tid, lastlsn，undoNextLsn, 用这个表我们可以找到每个事务最后一条 log 所在位置，方便进行 undo。dirty page table: 脏页表，每个条目记录第一次使该页不同于硬盘上的页的 lsn。该表可以让我们在恢复的时候更加方便的找到 redo start。Updates更新记录的基本操作如下这么做是为了保证日志的顺序和对页更新的顺序一致，如果顺序不一致，在 redo 的时候不一定能保证事务的一致性，比如写入覆盖这个问题。同时，注意修改 pageLsn 一定在 page 被修改过后，这是由于，考虑如下情况那么恢复的时候会认为该页的最后一条记录已经反应到磁盘上了，但实际上我们只修改了 pagelsn，具体内容对修改并没有反映到磁盘上。在对记录更新对时候，有一种特殊情况：插入，由于在插入数据之前我们并不知道它的 oid, 所以无法对其进行 lock，只有在我们获取了该页的 latch 并且知道插入位置之后才能获取到 lcok，但是在这种情况下可能会产生死锁。而且这种死锁不能被 lockmanager 所探测到。解决的方法如下，当我们向 lockmanager 发送一个立即返回的 condition lock 请求，此处的 condition 可以为 page.freeSpace() &gt; tuple.Size() &amp;&amp; dstSlot.free() 如果接受，那么按正常操作继续。如果没有，释放 latch，获取一个正常的 lock，该lock返回之后获取 latch，并检查该 slot 是否可用，如果不可用，则重复上述步骤（感觉自己理解还是有问题，原文如下）T o avoid waiting for a lock while holding a latch, which could lead to an undetected deadlock, the lock is requested conditionally, and if it is not granted, then the latch is released and the lock is requested unconditionally. Once the unconditionally requested lock is granted, the page is latched again, and any previously verified conditions are rechecked. This rechecking is required beacuse, after the page was unlatched, the conditions could have changed. The page_LSN, on relatching, if any changeds could have possibly occurred. If the conditions are still found to be satisfied for performing the update, it is performed as described above. Ohterwise, corrective actions are taken. If the conditionally requested lock is granted immediately, then the update can proceed as before.Total or Partial Rollbacks基本操作如下rollback 部分比较简单，不过这里 writelog 的时间点和前面有所不同，只有在操作被 undo 之后才会写 clr log，同时 clr log 里的 undoNextLSN 非常重要，当我们 total rollback 但中途 crash 的时候，我们可以利用 txnTable 里的 lastLsn，直接找到对应下一条该重做的 log，提升了恢复速度。为什么要在 undo 之后写 log，主要原因和上面差不多，如果提前写 log，就会存在虚空 undo 的情况，导致少撤销一条操作。CheckpointsARIES 采取了 fuzzy checkpoint 技术，fuzzy checkpoint 也就是说，当我们进行 checkpoint 操作的时候不需要 stw，我们只是记录一些元信息，方便更快的恢复，不过这也需要和 bufferpoolmanager 进行配合，需要 bpm 定时向硬盘写入 pagebuffer，减少恢复所需的工作量。fuzzy checkpoint 的基本操作如下，当系统进行 checkpoint 操作的时候，首先向日志写入 checkpoint_start, 然后写入 dirty page table, txn table，之后标注 checkpoint_end, 最后将 master-record 指向的记录改为当前 checkpoint_start 所在位置。Analysis Pass这阶段的目的是完善 dpt 和 txnTable, 当我们 crash 的时候，checkpoint 之后的操作也需要进行 redo 和 undo，而这部分的信息并没有包含在 checkpoint 的两张表内，我们需要借助当前 pass 进行补全。当前 pass 会产生 txnTable, dpt, redoLsn 三个数据结构，用于接下来两个 pass 的操作。 redoLsn 是在 dpt 里最小的 reclsn，如果 dpt 为空，也就是说没有修改发生，那么我们就没必要进行 redo。当前 pass 如何构造 dpt, txnTabledpt: 对遇到的每条记录，如果所做修改的的页没有在 dpt 中出现，dpt.append(lsn, lsn)txnTable: 对遇到的每条记录，如果指明了某个事务结束，则从 txnTable 中移除，否则更新 txntable 的状态，即更新 txnTable 对应条目的 undoNextLsn, lastLsn, stateRedo Passredo 只需要从 redoLsn 开始向后重做就好了，不过要检查几个要素，要被 redo 的页是否在 dpt 中，当前 lsn 是否大于等于该页的 recLsn，该页的 pageLsn 是否小于该 log 的lsn。当我们 redo 的时候，有可能会从 checkpoint 前某个点开始 redo，这样就会造成部分页已经被写入了硬盘并且日后也未被修改，所以 checkpoint 的时候不在 dpt 当中，不需要被修改。关于 pageLsn，如果 pageLsn 大于当前 lsn，即证明该条记录所做的操作已经落盘，不需要进行重做，而且我们的 recLsn 需要更新，更新为比 pageLsn 大一点的记录。由于 pageLsn 只在 redo 的时候需要，这么做也是可以的。redo 部分可以发挥并行优势，因为我们的 redo 是面向 page 的，也就是说对于 dpt 的所有 page，我们都可以进行并行操作，只要事先/或者流水线 准备好对应 page 的 log queue，依次执行即可。Undo Pass因为之前的 redo pass, 当前要做的只是把 crash 时刻没有完成的事务撤销而已。undo 部分的操作和前面 rollback 基本一致，不同的是这里取得 undoNextLsn 是从 txnTable。Checkpoints During RestartAnalysis Pass 在完成这个 pass 之后，我们将现在的 dpt/txnTable 写入到硬盘上，这样下次恢复的时候就可以跳过 Analysis pass.Redo Pass 每次 bufferpool 向磁盘写入修改过后的页的时候，就更新该页的记录为当前 log 的下一条记录，由于 redo 是从前往后，所以同样保证了 wal 的性质。并且，在这种情况下，我们下次重启的时候就可以少一些 redo。其他记录 checkpoint 相关的记录保持不变。Undo Pass 在启动 undo pass 的时候，将 dpt 更新为现在 bufferpoll 的 dpt，很容易理解，在下次进行重启操作的时候只要由于前面两个 pass 的操作，可以减少工作量。原文ARIES : A Transaction Recovery Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging"},{"title":"为什么我们要计算 First Set/ Follow Set","date":"2020-03-16T05:33:34.000Z","url":"/2020/03/16/firstfllow/","tags":["compiler","recursive descent"],"categories":["笔记本"],"content":"在递归下降 parse 当中，在某些情况下，我们会计算 First Set/ Follow Set。为什么要计算它们呢？假设我们有如下语法首先，注意到 B production 是一个左递归，递归下降不能处理左递归的情况。得把 B 变为右递归，我们做如下变化First Set当我们获得第一个 token 的时候，首先要和 S 进行匹配，但此时 AB 都是非终结符，我们需要一种可以和现有 token 匹配但方法，这就是 First set（first集），我们把 tkn 和 First(A) 进行匹配，完成我们递归下降的过程。理解到了 First 集合的含义，那如何计算 First 集也是信手拈来。First(A) 就是，按照 A 的推到走下去，可能遇到的第一个终结符。匹配 A 会有哪些终结符。我们的两个集合都是为了匹配 token 服务的。那么很容易得到计算 First(A) 的方法：注意这里，当 C 为 ε 的时候，下一个要匹配的就变成了 a。Follow SetFollow Set 是为了解决我们推到过程中遇到一个非终结符，这个非终结符可能为 ε 诞生的，它同样是计算接下来要可能的终结符。举个例。假设 A 为空，A 后可能为 C, B。"},{"title":"NFA & DFA","date":"2020-03-14T11:28:53.000Z","url":"/2020/03/14/NFA-DFA/","tags":["NFA","DFA","compiler"],"categories":["笔记本"],"content":"看 DFA, NFA 有点头大，记一下，理一下流程。NFANFA 可被 $(Q,\\Sigma, T, q0, F)$ 定义，其中$Q$ 为状态的有限集合$\\Sigma$ 为输入字符集$T$ 为转移函数， 可以表示为 $Q\\times \\Sigma \\to P(Q)$ ，因为每个状态有输入和输出，输入为$\\Sigma$，输出就是下一个状态，在 NFA 中，下一个状态不唯一，所以下个状态表示为 $P(Q)$ ，也就是说 $Q$ 的幂集合$q_0$ 为起始状态在带有 $\\varepsilon$移动 的状态下，NFA 可被扩展为 $NFA-\\varepsilon$ 或者说 $NFA-\\lambda$ ，那么此时的 $T$ 可以表示为 $Q\\times (\\Sigma \\cup \\{\\varepsilon\\}) \\to P(Q)$$\\varepsilon$ 移动， 即使说一个状态在没有输入的状况下转化为其他状态，也就是说，当前状态不确定，薛定谔的状态DFADFA 和 NFA 可以互相转化，与 NFA 不同，DFA 在一个输入下只有唯一的一种后继状态，DFA 可以表示为 $Q\\times\\Sigma\\to Q$ 由于 DFA 的性质，还可以写成 $Q\\times\\Sigma^{*}\\to Q$ NFA to DFA即由 $Q\\times\\Sigma\\to P(Q)\\Rightarrow Q\\times\\Sigma\\to Q$，很显然的一个想法是令$Q\\in P(Q)$，也就是说，把 NFA 中由一个输入产生的多个后继状态在不改变 NFA 的情况下组合成一个。这种转换的方法叫幂集构造，由上述公式的变化，易知：如果我们有一个$n$个状态的 NFA，当把它变为 DFA 的时候，我们最多会有 $2^n$ 个状态。如何应用 DFA 来识别 token ?首先我们要把语言划分成不同到成分，即不同到 class，然后如何识别呢？对于每个 class 我们可以定义相应到 DFA ，这可以用语言自带的库实现，比如字符串对比，正则表达式。然后我们只要把不同部分的 DFA 组合到一起形成一个大的 DFA 就可以了。例子在对 sql 进行词法分析对过程中，有个例子就是，当输入为[a-zA-Z]的时候，下一个状态是不确定的，有可能为 Identifier 也可能为 Keyword，即如下 NFA通过魔法，可以转化为如下 DFA实际上，在转换为 DFA 之后，switch 写一下 lexer 就写完了。最近正好在写 sql 的 lexer，看到了几个例子，这里记一下。在 SQL 里，如何快速识别出关键字(KEYWORD)是分析速度最大的影响因素。我看到有两种实现。用 hash 表实现，$O(1)$用 字典🌲 实现， $O(1)$顺序查找，$O(N)$字典树是跑的最快的，因为 hash 表在最差的情况下可能到 $O(N)$ ，当然这也要看 hash 表到实现，但是字典树到最差情况就是 $O(max(len(keyword)))$ ，只要$max(len(keyword))&lt;num_keywords$ 那么字典树就绝对更快。 ping-cap 的 sql parser 就是这么写的。ref:DFA wikiNFA wikipingcap sqlparser"}]